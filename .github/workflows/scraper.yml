name: DamaDam Scraperüíô

on:
  schedule:
    - cron: "*/30 * * * *"      # ‚ñ∂Ô∏è Every 30 minutes
  workflow_dispatch:            # ‚ñ∂Ô∏è Manual run

jobs:
  run-bot:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    - name: Install Chrome
      uses: browser-actions/setup-chrome@v1

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    # -------------------------------------------
    # 1Ô∏è‚É£ Load credentials JSON from Secrets
    # -------------------------------------------
    - name: Write Google Credentials File
      run: |
        echo "${{ secrets.DD_CREDENTIALS_JSON }}" > credentials.json

    # -------------------------------------------
    # 2Ô∏è‚É£ Export environment variables for Python
    # -------------------------------------------
    - name: Set Env Vars
      run: |
        echo "DD_LOGIN_EMAIL=${{ secrets.DD_LOGIN_EMAIL }}" >> $GITHUB_ENV
        echo "DD_LOGIN_PASS=${{ secrets.DD_LOGIN_PASS }}" >> $GITHUB_ENV
        echo "DD_SHEET_ID=${{ secrets.DD_SHEET_ID }}" >> $GITHUB_ENV
        echo "COOKIE_FILE=${{ secrets.COOKIE_FILE }}" >> $GITHUB_ENV
        echo "CREDENTIALS_FILE=credentials.json" >> $GITHUB_ENV

    # -------------------------------------------
    # 3Ô∏è‚É£ Run Main Scraper
    # -------------------------------------------
    - name: Run Scraper
      run: |
        python Scraper.py
